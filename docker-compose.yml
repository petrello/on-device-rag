services:
  # Qdrant Vector Database
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant_db
    restart: unless-stopped
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC API (optional)
    volumes:
      - ./qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Edge RAG Application
  rag-app:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - PYTHON_VERSION=3.12
    container_name: streamlit_rag
    restart: unless-stopped
    depends_on:
      qdrant:
        condition: service_healthy
    volumes:
      # Application code (for development hot-reload)
      - .:/app
      # Persistent data directories
      - ./data:/app/data
      - ./models:/app/models
      - ./embeddings:/app/embeddings
      # Optional: Local FAISS storage
      - ./storage:/app/storage
    ports:
      - "8501:8501"  # Streamlit UI
      - "8001:8001"  # Prometheus metrics (optional)
    environment:
      # Vector Store Configuration
      - QDRANT_URL=http://qdrant:6333
      - VECTOR_STORE_TYPE=qdrant
      - QDRANT_COLLECTION=on_device_rag

      # Model Configuration
      - EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
      - HF_HOME=/app/embeddings

      # Memory Optimization
      - LLM_MAX_TOKENS=2048
      - LLM_CONTEXT_WINDOW=4096
      - LLM_THREADS=4
      - MAX_CHAT_HISTORY=10
      - AUTO_CLEANUP_THRESHOLD_MB=6000

      # Feature Flags
      - USE_HIERARCHICAL_CHUNKING=true
      - USE_HYBRID_SEARCH=true
      - ENABLE_CONVERSATION_MEMORY=true
      - ENABLE_CITATIONS=true
      - ENABLE_METRICS=true

      # Logging
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json

      # Python Optimization
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
    deploy:
      resources:
        limits:
          memory: 6G      # Adjust based on available RAM
          cpus: '4'       # Adjust based on available CPU cores
        reservations:
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/_stcore/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s  # Allow time for model loading

  # Optional: Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    profiles:
      - monitoring

  # Optional: Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    profiles:
      - monitoring

volumes:
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  default:
    name: on-device-rag-network
    driver: bridge