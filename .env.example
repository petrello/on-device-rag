# ============================================================================
# On-Device RAG Configuration
# ============================================================================
# Copy this file to .env and adjust values as needed.
# All settings have sensible defaults; only override what you need.

# ============================================================================
# PATHS
# ============================================================================
DATA_DIR=data
MODELS_DIR=models
EMBEDDINGS_DIR=embeddings

# ============================================================================
# VECTOR STORE
# ============================================================================
# Backend: "qdrant" (recommended) or "faiss" (offline/lightweight)
VECTOR_STORE_TYPE=qdrant

# Qdrant settings
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=edge_rag

# FAISS settings
FAISS_INDEX_PATH=faiss_storage/faiss_index

# ============================================================================
# MODELS
# ============================================================================
# Embedding model (HuggingFace identifier)
EMBEDDING_MODEL=ibm-granite/granite-embedding-278m-multilingual
EMBEDDING_DIM=768

# LLM model path (GGUF format, relative to project root)
LLM_MODEL_PATH=models/llama-3.2-1b-instruct-q8_0.gguf

# ============================================================================
# LLM PARAMETERS
# ============================================================================
# Generation temperature (0.0 = deterministic)
LLM_TEMPERATURE=0.0

# Maximum tokens to generate
LLM_MAX_TOKENS=2048

# Context window size
LLM_CONTEXT_WINDOW=8192

# CPU threads for inference (default: 4)
LLM_THREADS=4

# Batch size for token processing
LLM_BATCH_SIZE=512

# Enable prompt caching for faster responses
LLM_ENABLE_PROMPT_CACHE=true

# ============================================================================
# CHUNKING
# ============================================================================
# Child chunk size for retrieval
CHUNK_SIZE=400

# Overlap between chunks
CHUNK_OVERLAP=40

# Enable hierarchical chunking (parent-child)
USE_HIERARCHICAL_CHUNKING=false

# Parent chunk size
PARENT_CHUNK_SIZE=1200

# ============================================================================
# RETRIEVAL
# ============================================================================
# Number of chunks to retrieve
SIMILARITY_TOP_K=3

# Enable hybrid search (vector + BM25)
USE_HYBRID_SEARCH=false

# Hybrid alpha (1.0 = pure vector, 0.0 = pure BM25)
HYBRID_ALPHA=0.7

# ============================================================================
# MEMORY
# ============================================================================
# Maximum chat history to display
MAX_CHAT_HISTORY=10

# Memory cleanup threshold (MB)
AUTO_CLEANUP_THRESHOLD_MB=5000

# Enable memory profiling
ENABLE_MEMORY_PROFILING=false

# ============================================================================
# CONVERSATION
# ============================================================================
# Enable multi-turn conversation context
ENABLE_CONVERSATION_MEMORY=true

# Number of exchange pairs to remember
MEMORY_WINDOW=5

# ============================================================================
# CITATIONS
# ============================================================================
# Enable source citations in responses
ENABLE_CITATIONS=true

# Characters of context around citations
CITATION_HIGHLIGHT_LENGTH=200

# ============================================================================
# MONITORING
# ============================================================================
# Enable Prometheus metrics
ENABLE_METRICS=true

# Metrics server port
METRICS_PORT=8001

# Log format: "json" or "text"
LOG_FORMAT=json

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# ============================================================================
# DOCUMENT MANAGEMENT
# ============================================================================
# Maximum upload size (MB)
MAX_UPLOAD_SIZE_MB=50

# Allowed file extensions
ALLOWED_EXTENSIONS=pdf,txt,docx,md

