# Core RAG Framework
llama-index-core==0.11.20
llama-index-llms-llama-cpp==0.3.1
llama-index-embeddings-huggingface==0.3.1

# Vector Stores
llama-index-vector-stores-qdrant==0.3.1
qdrant-client==1.11.3
faiss-cpu==1.8.0  # Alternative local vector store

# Document Processing
pypdf==4.3.1
python-docx==1.1.2
python-magic==0.4.27  # File type detection

# Hybrid Search (BM25)
rank-bm25==0.2.2

# Web Framework
streamlit==1.39.0

# Monitoring & Metrics
prometheus-client==0.21.0
psutil==6.1.0  # Memory profiling (optional)

# Logging
structlog==24.4.0

# Configuration Management
pydantic==2.9.2
pydantic-settings==2.6.1
python-dotenv==1.0.1

# Utilities
numpy==1.26.4
pandas==2.2.3  # Data manipulation (optional, for analytics)

# Testing (Development)
pytest==8.3.3
pytest-cov==5.0.0
pytest-asyncio==0.24.0

# Type Checking (Development)
mypy==1.13.0

# Code Quality (Development)
black==24.10.0
ruff==0.7.4

# Optional: Advanced Features
# sentence-transformers==3.3.1  # Alternative embedding models
# transformers==4.46.3  # Hugging Face models
# torch==2.5.1  # PyTorch (only if using transformer models)

# Note: llama-cpp-python is installed separately in Dockerfile
# with CMAKE_ARGS for optimal CPU performance